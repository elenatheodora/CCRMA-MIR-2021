{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NB1: MIR Review & Tools.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUTGCItXIDYl"
      },
      "source": [
        "#MIR Week 1 Day 1\n",
        "\n",
        "CCRMA MIR workshop 2021, Notebook by Elena Georgieva & Iran Roman\n",
        "\n",
        "###Today's Goal: Review 'basic' concepts from MIR, review Python, and learn about existing MIR tools.\n",
        "\n",
        "Instructions: Complete the sections below, filling in code or responses where marked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGPSIt1nMSt0"
      },
      "source": [
        "First, we load in our audio files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6ci3GnsX2e",
        "outputId": "97641295-cf37-4e0f-f1fd-cdb61c49f4b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!ls drive/MyDrive/CCRMA_MIR_2021/audio\n",
        "\n",
        "drums = 'drive/MyDrive/CCRMA_MIR_2021/audio/drums.aif'\n",
        "violin = 'drive/MyDrive/CCRMA_MIR_2021/audio/violin.wav'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "drums.aif  flute.aif  guitar.aif  piano.wav  trumpet.aif  violin.wav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayLxtvOuIXVl"
      },
      "source": [
        "## Part 1: Reading Audio\n",
        "\n",
        "Librosa is a Python package for music and audio processing.\n",
        "\n",
        "1. First, import librosa. Then, use librosa.load to load the 'drums' audio file into an audio array. You'll need a variable to store the audio array and a variable to store the sampling rate (fs or sr are common choices). \n",
        "2. Display the length of the signal and the sampling rate.\n",
        "\n",
        "\n",
        "### Discuss: Sampling Rate\n",
        "What is sampling rate?\n",
        "Why do we need a sampling rate for digital audio?\n",
        "What are common choices for sampling rates?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "H8ECKlvVIkiF",
        "outputId": "f883d781-a074-4470-9b4b-25d079a95316"
      },
      "source": [
        "import ___\n",
        "\n",
        "x, fs = ____\n",
        "\n",
        "print('Signal Shape:', ___)\n",
        "print('Sampling Rate:', ___)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dc5d8b449bcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0m___\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Signal Shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m___\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '___'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Zs2hQtLgwd"
      },
      "source": [
        "## Part 2: Playing Audio\n",
        "\n",
        "IPython is another Python package we will use here. \n",
        "1. import IPython.display as ipd\n",
        "2. Use IPython Audio to load and play the 'drums' audio file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufyHiUxFLj_V"
      },
      "source": [
        "import ___\n",
        "ipd.Audio(__, ___) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuQev7Z3HKQZ"
      },
      "source": [
        "## Part 2b: Read and Play the violin audio file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttf8IU0cHUW1"
      },
      "source": [
        "## Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmPYeVdNLqV3"
      },
      "source": [
        "## Part 3: Visualizing Audio\n",
        "\n",
        "1. Matplotlib is another Python library used for plotting. Import matplotlib.pyplot as plt.\n",
        "2. Create a new figure using plt.figure\n",
        "3. Use librosa.display.waveplot to display our drum signal and our violin signal. Do they look different?\n",
        "4. Extra: Try to plot only some of the violin audio file, so it matches the length of the drum audio file. \n",
        "5. Extra: Add titles to your plots\n",
        "\n",
        "Notice, this visualization is in the time domain (i.e. time is on the x axis). \n",
        "\n",
        "Discuss: Where have you seen audio represented like this?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAFBNv_fLszI"
      },
      "source": [
        "## Your Code Here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa_9wqxIZGVI"
      },
      "source": [
        "## Part 4: Audio Features\n",
        "\n",
        "Now we've plotted our signal, cool! How much information can we get from those plots?\n",
        "\n",
        "Sometimes a bit of information. Sometimes... not much. We use some **audio features** to help us learn more about our audio file. \n",
        "\n",
        "We'll look at Spectral Centroid, RMS, and Zero-Crossing Rate.  \n",
        "\n",
        "\n",
        "### Spectral Centroid\n",
        "**Spectral centroid**: indicates at which frequency the energy of a spectrum is centered upon. (Wikipedia [link text](https://en.wikipedia.org/wiki/Spectral_centroid))\n",
        "\n",
        "\n",
        "### RMS Energy\n",
        "The **energy** of a signal is the total magntiude of the signal. For audio, that roughly corresponds to how loud the signal is. The **RMS Energy ** is the root mean square of the energy. (Wikipedia [link text](https://en.wikipedia.org/wiki/Audio_power))\n",
        "\n",
        "\\begin{equation}\n",
        "\\sqrt{ \\frac{1}{N} \\sum_n \\left| x(n) \\right|^2 }\n",
        "\\end{equation}\n",
        "\n",
        "### Zero Crossing Rate\n",
        "**Zero Crossing Rate**: The number of time a signal crosses the horizontal axis. (Wikipedia [link text](https://en.wikipedia.org/wiki/Zero-crossing_rate))\n",
        "\n",
        "1. Two functions are proivided below. What does extract_features do? What does plot_features do?\n",
        "2. Use these to learn more about the drums audio file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csmQua0aa9pn"
      },
      "source": [
        "def extract_feature(x, feature, win_length):\n",
        "    hop_length = int(win_length/2)\n",
        "    spec_cent = librosa.feature.spectral_centroid(x, 44100)[0] \n",
        "    rms = librosa.feature.rms(x, win_length, hop_length)[0] \n",
        "    zcr = librosa.feature.zero_crossing_rate(x,win_length, hop_length)[0] \n",
        "    if feature == \"spec_cent\": \n",
        "        return spec_cent\n",
        "    if feature == \"rms\":\n",
        "        return rms\n",
        "    if feature == \"zcr\":\n",
        "        return zcr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tYZbwiZbDT0"
      },
      "source": [
        "def plot_features(x, fs, win_length):\n",
        "    spec_cent = extract_feature(x, \"spec_cent\", win_length) # Calls above functions\n",
        "    rms = extract_feature(x, \"rms\", win_length)\n",
        "    zcr = extract_feature(x, \"zcr\", win_length)\n",
        "\n",
        "    # change from samples to time\n",
        "    hop_length = int(win_length/2)\n",
        "    frames = range(len(x))\n",
        "    t = librosa.frames_to_time(frames, hop_length)\n",
        "    plt.figure(figsize=(15, 17))\n",
        "    ax = plt.subplot(4, 1, 1)\n",
        "    librosa.display.waveplot(x, fs);\n",
        "    plt.title(\"Audio File\")\n",
        "\n",
        "    frames = range(len(spec_cent))\n",
        "    t = librosa.frames_to_time(frames, hop_length)\n",
        "    plt.subplot(4, 1, 2)\n",
        "    plt.plot(spec_cent)\n",
        "    plt.title(\"Spec_cent\")\n",
        "\n",
        "    frames = range(len(rms))\n",
        "    t = librosa.frames_to_time(frames, hop_length)\n",
        "    plt.subplot(4, 1, 3)\n",
        "    plt.plot(t, rms)\n",
        "    plt.title(\"RMS\")\n",
        "    \n",
        "    frames = range(len(zcr))\n",
        "    t = librosa.frames_to_time(frames, hop_length)\n",
        "    plt.subplot(4, 1, 4)\n",
        "    plt.plot(t, zcr)\n",
        "    plt.title(\"ZCR\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExaM58wBbTer"
      },
      "source": [
        "## Your Code Here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PoVdqs3MNsQ"
      },
      "source": [
        "## Part 5: Fourier Transform\n",
        "\n",
        "The Fourier Transform is one of the most fundamental operations in applied mathematics and signal processing.\n",
        "\n",
        "It transforms our **time-domain signal** into the **frequency domain**. The time domain we have above expresses our signal as a sequence of samples, and the frequency domain expresses our signal as a superposition of sinusoids of varying magnitudes, frequencies, and phase offsets.\n",
        "[\n",
        "(Wikipedia.)](https://https://en.wikipedia.org/wiki/Fourier_transform)\n",
        "\n",
        "1. import numpy as np and import scipy\n",
        "2. Compute a Fourier Transform\n",
        "3. Plot the spectrum and play around with the plot (\"zooming in\") such that the peaks are clear.\n",
        "4. Do this for both the drums and the violin audios\n",
        "\n",
        "Notice, we are now in the frequency domain (i.e. frequency is on the x axis). \n",
        "\n",
        "Discuss: What do you see? When is this visualization more useful than the time-domain visualization in the previous section?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyTGnZEKM0QP"
      },
      "source": [
        "## Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nz-qqfjLzfS"
      },
      "source": [
        "## Part 6: STFT\n",
        "\n",
        "Music signals change over time. It's rather meaningless to compute a single Fourier Transform over a whole song. \n",
        "\n",
        "Short-time Fourier transform (STFT) is obtained by computing the Fourier transform like above but for successive frames in a signal. [You can read more about the STFT on Wikipedia](https://https://en.wikipedia.org/wiki/Short-time_Fourier_transform). \n",
        "\n",
        "\n",
        "1. Use librosa.stft to compute an STFT. Please use a hop length of 512 and a frame size of 2048 (these are somewhat standard selections). \n",
        "2. Print the shape of the STFT. \n",
        "3. Do this for both the Drum and Violin signals."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMEvvKjKPnNr"
      },
      "source": [
        "## Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTtCBQ9WN2Lr"
      },
      "source": [
        "##Part 7: Spectrograms \n",
        "\n",
        "The STFT we did above is the first step towards making a spectrogram!\n",
        "What is a spectrogram? Let's try one out! \n",
        "\n",
        "\n",
        "[Harvard The Music Lab Spectrogram](https://musiclab.chromeexperiments.com/spectrogram/)\n",
        "\n",
        "A spectrogram shows the intensities of frequencies over time. It is simply the squared magnitude of the stft.\n",
        "\n",
        "1. Use librosa.amplitude_to_db to take the log amplitude of our STFT above. We do this because human perception of sound intensity is logarithmic.\n",
        "2. Use librosa.display.specshow to print out our spectrogram. \n",
        "3. You can also use the following line to add a legend for the plot: plt.colorbar(format='%+2.0f dB')\n",
        "4. Do this for both the drum and violin signals. \n",
        "\n",
        "Discuss: How different do the drum and violin signals look? Can you tell which is which?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyJ52IzIL1sM"
      },
      "source": [
        "## Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xWiJMiKMAsT"
      },
      "source": [
        "## Part 7b: Mel Spectrogram\n",
        "\n",
        "Next, let's do a Mel spectrogram. Human perception of sound intensity is logarithmic. Therefore, like the STFT, we are interested in the log amplitude.\n",
        "\n",
        "1. Use librosa.feature.melspectrogram to create a mel spectroram.\n",
        "2. use librosa.power_to_db \n",
        "3. Display the new spectrogram using librosa.display.specshow. Include a title and the colorbar as above.\n",
        "4. Do this for both the drums and violin.\n",
        "\n",
        "What do you see? How does it compare to The Music Lab's spectrogram demo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiIq-_S0MEyB"
      },
      "source": [
        "## Your Code Here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUOyWueCtWlM"
      },
      "source": [
        "# Great work! \n",
        "\n",
        "## Questions??"
      ]
    }
  ]
}